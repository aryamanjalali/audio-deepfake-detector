# Robust Audio Deepfake Detection Under Real-World Compression

A research-grade system for detecting audio deepfakes that have been compressed through real-world channels (WhatsApp, Instagram, TikTok, phone calls). This project evaluates detector robustness under realistic codec pipelines and implements techniques to improve it.

## ğŸ¯ Project Highlights

- **Multi-Dataset Evaluation**: Trained and tested on ASVspoof 2019/2021, WaveFake, and FakeAVCeleb
- **Real-World Robustness**: Simulates 10+ compression scenarios (AAC, Opus, MP3 at various bitrates)
- **3 Detection Approaches**: 
  - Baseline Spectrogram CNN
  - Data-Augmented CNN (compression-robust)
  - Fine-tuned wav2vec2 (transfer learning)
- **Public Demo**: Interactive Gradio app deployed on HuggingFace Spaces

## ğŸš€ Quick Start

### Installation

```bash
# Clone or navigate to the repository
cd audio-deepfake-detector

# Run automated setup (creates venv and installs dependencies)
./setup.sh

# Activate virtual environment (required for all commands)
source venv/bin/activate

# OR use the run.sh helper (auto-activates venv)
./run.sh python scripts/quickstart.py
```

**Note**: macOS Python 3.13+ requires a virtual environment. The `setup.sh` script handles this automatically.

### Download Datasets

```bash
# Make sure venv is activated: source venv/bin/activate

# Get download instructions
python scripts/download_datasets.py

# OR use helper script
./run.sh python scripts/download_datasets.py
```

### Train Models

```bash
# 1. Train baseline model (clean audio only)
python src/training/train.py --config experiments/configs/baseline.yaml

# 2. Train data-augmented model
python src/training/train.py --config experiments/configs/augmented.yaml

# 3. Fine-tune wav2vec2
python src/training/train.py --config experiments/configs/wav2vec2.yaml
```

### Run Robustness Experiments

```bash
# Evaluate all models on compressed audio variants
python src/training/evaluate.py --experiment robustness_analysis
```

### Launch Demo Locally

```bash
cd demo
python app.py
```

Visit `http://localhost:7860` to use the interface.

## ğŸ“ Project Structure

```
audio-deepfake-detector/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original datasets
â”‚   â”œâ”€â”€ processed/              # Preprocessed features
â”‚   â””â”€â”€ simulated/              # Codec-transformed variants
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocessing.py    # Audio normalization, spectrograms
â”‚   â”‚   â”œâ”€â”€ codec_simulator.py  # ffmpeg pipeline simulator
â”‚   â”‚   â””â”€â”€ dataset.py          # PyTorch dataset loaders
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ baseline_cnn.py     # Spectrogram CNN
â”‚   â”‚   â”œâ”€â”€ augmented_cnn.py    # Data-augmented variant
â”‚   â”‚   â””â”€â”€ wav2vec2_model.py   # Pretrained embedding model
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train.py            # Training script
â”‚   â”‚   â””â”€â”€ evaluate.py         # Evaluation and visualization
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ audio_utils.py      # Audio processing helpers
â”‚       â””â”€â”€ metrics.py          # ROC AUC, confusion matrix, etc.
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ configs/                # Training configurations
â”‚   â”œâ”€â”€ notebooks/              # Analysis notebooks
â”‚   â””â”€â”€ results/                # Metrics, plots, checkpoints
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ app.py                  # Gradio interface
â”‚   â””â”€â”€ README.md               # HuggingFace Space docs
â””â”€â”€ tests/                      # Unit tests
```

## ğŸ”¬ Research Questions Addressed

1. **How fragile are audio deepfake detectors to realistic re-encoding?**
2. **Which codecs and bitrates are most harmful (or helpful) for detection?**
3. **Does training with realistic channel simulations improve robustness?**
4. **Are pretrained audio representations more resilient to compression?**

## ğŸ“Š Key Findings

*(To be populated after experiments)*

## ğŸ¨ Demo Features

- Upload audio files for deepfake detection
- Simulate real-world compression (WhatsApp, Instagram, Phone, Custom)
- Compare 3 model architectures
- Visualize spectrogram and prediction confidence
- Educational explanations of results

## ğŸ”§ Technical Details

### Codec Simulation Pipeline

- **AAC**: 128k, 64k, 32k bitrates
- **Opus**: 64k, 24k bitrates
- **MP3**: 128k, 64k, 32k bitrates
- **Sample rates**: 48kHz â†’ 16kHz â†’ 8kHz
- **Social media chains**: WhatsApp (16kHz mono Opus 24k), Instagram (AAC re-encode), Phone (8kHz narrowband)

### Model Architectures

**Baseline CNN**: ResNet-18 style architecture on log-mel spectrograms (128 mel bins, 1-3s windows)

**Augmented CNN**: Same architecture, trained with on-the-fly codec augmentation

**wav2vec2**: HuggingFace wav2vec2-base with fine-tuned classification head

## ğŸ“ˆ Results Summary

*(Results table to be added after experiments)*

## ğŸš¢ Deployment

The demo is deployed on HuggingFace Spaces: [Link TBD]

## ğŸ“ Citation

If you use this work, please cite:

```
[Your citation format]
```

## ğŸ“„ License

MIT License (or your preferred license)

## ğŸ™ Acknowledgments

- ASVspoof Challenge organizers
- WaveFake dataset creators
- FakeAVCeleb dataset creators
- HuggingFace for wav2vec2 and Spaces hosting
